{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>removed_punc</th>\n",
       "      <th>tokens</th>\n",
       "      <th>filtered_tokens</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>lemma_words</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "      <td>House Dem Aide We Didn’t Even See Comey’s Lett...</td>\n",
       "      <td>['house', 'dem', 'aide', 'we', 'didn’t', 'even...</td>\n",
       "      <td>['house', 'aide', 'didn’t', 'even', 'comey’s',...</td>\n",
       "      <td>['house', 'aide', 'didn’t', 'even', 'comey’s',...</td>\n",
       "      <td>['house', 'aide', 'didn’t', 'even', 'comey’s',...</td>\n",
       "      <td>house aide didn’t even comey’s letter jason ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>['ever', 'get', 'the', 'feeling', 'your', 'lif...</td>\n",
       "      <td>['ever', 'feeling', 'your', 'life', 'circles',...</td>\n",
       "      <td>['ever', 'feeling', 'life', 'circles', 'rounda...</td>\n",
       "      <td>['ever', 'feeling', 'life', 'circle', 'roundab...</td>\n",
       "      <td>ever feeling life circle roundabout rather hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29 2...</td>\n",
       "      <td>['why', 'the', 'truth', 'might', 'get', 'you',...</td>\n",
       "      <td>['truth', 'might', 'fired', 'october', '2016',...</td>\n",
       "      <td>['truth', 'might', 'fired', 'october', '2016',...</td>\n",
       "      <td>['truth', 'might', 'fired', 'october', '2016',...</td>\n",
       "      <td>truth might fired october 2016 tension intelli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>['videos', '15', 'civilians', 'killed', 'in', ...</td>\n",
       "      <td>['videos', 'civilians', 'killed', 'single', 'a...</td>\n",
       "      <td>['videos', 'civilians', 'killed', 'single', 'a...</td>\n",
       "      <td>['video', 'civilian', 'killed', 'single', 'air...</td>\n",
       "      <td>video civilian killed single airstrike identif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>['print', 'an', 'iranian', 'woman', 'has', 'be...</td>\n",
       "      <td>['print', 'iranian', 'woman', 'been', 'sentenc...</td>\n",
       "      <td>['print', 'iranian', 'woman', 'sentenced', 'ye...</td>\n",
       "      <td>['print', 'iranian', 'woman', 'sentenced', 'ye...</td>\n",
       "      <td>print iranian woman sentenced year prison iran...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title              author  \\\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1   \n",
       "1  Ever get the feeling your life circles the rou...      0   \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1   \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1   \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1   \n",
       "\n",
       "                                        removed_punc  \\\n",
       "0  House Dem Aide We Didn’t Even See Comey’s Lett...   \n",
       "1  Ever get the feeling your life circles the rou...   \n",
       "2  Why the Truth Might Get You Fired October 29 2...   \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...   \n",
       "4  Print \\nAn Iranian woman has been sentenced to...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['house', 'dem', 'aide', 'we', 'didn’t', 'even...   \n",
       "1  ['ever', 'get', 'the', 'feeling', 'your', 'lif...   \n",
       "2  ['why', 'the', 'truth', 'might', 'get', 'you',...   \n",
       "3  ['videos', '15', 'civilians', 'killed', 'in', ...   \n",
       "4  ['print', 'an', 'iranian', 'woman', 'has', 'be...   \n",
       "\n",
       "                                     filtered_tokens  \\\n",
       "0  ['house', 'aide', 'didn’t', 'even', 'comey’s',...   \n",
       "1  ['ever', 'feeling', 'your', 'life', 'circles',...   \n",
       "2  ['truth', 'might', 'fired', 'october', '2016',...   \n",
       "3  ['videos', 'civilians', 'killed', 'single', 'a...   \n",
       "4  ['print', 'iranian', 'woman', 'been', 'sentenc...   \n",
       "\n",
       "                                        clean_tokens  \\\n",
       "0  ['house', 'aide', 'didn’t', 'even', 'comey’s',...   \n",
       "1  ['ever', 'feeling', 'life', 'circles', 'rounda...   \n",
       "2  ['truth', 'might', 'fired', 'october', '2016',...   \n",
       "3  ['videos', 'civilians', 'killed', 'single', 'a...   \n",
       "4  ['print', 'iranian', 'woman', 'sentenced', 'ye...   \n",
       "\n",
       "                                         lemma_words  \\\n",
       "0  ['house', 'aide', 'didn’t', 'even', 'comey’s',...   \n",
       "1  ['ever', 'feeling', 'life', 'circle', 'roundab...   \n",
       "2  ['truth', 'might', 'fired', 'october', '2016',...   \n",
       "3  ['video', 'civilian', 'killed', 'single', 'air...   \n",
       "4  ['print', 'iranian', 'woman', 'sentenced', 'ye...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  house aide didn’t even comey’s letter jason ch...  \n",
       "1  ever feeling life circle roundabout rather hea...  \n",
       "2  truth might fired october 2016 tension intelli...  \n",
       "3  video civilian killed single airstrike identif...  \n",
       "4  print iranian woman sentenced year prison iran...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/preprocessed_train.csv', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['title']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14533,)\n",
      "(3634,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(14533, 18476)\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.30940996 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "(3634, 18476)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf_train = tfidf.fit_transform(X_train)\n",
    "tfidf_test = tfidf.transform(X_test)\n",
    "\n",
    "print(tfidf_train.toarray())\n",
    "print(tfidf_train.shape)\n",
    "print(tfidf_test.toarray())\n",
    "print(tfidf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.9320308200330215\n",
      "Cross val score : [0.93188854 0.93326453 0.93257654 0.92980041 0.92670337]\n",
      "Confusion matrix : \n",
      " [[1904  147]\n",
      " [ 100 1483]]\n"
     ]
    }
   ],
   "source": [
    "pac = PassiveAggressiveClassifier(max_iter=50)\n",
    "pac.fit(tfidf_train, y_train)\n",
    "\n",
    "pred = pac.predict(tfidf_test)\n",
    "print(\"Accuracy score : {}\".format(accuracy_score(y_test, pred)))\n",
    "print(\"Cross val score : {}\".format(cross_val_score(pac, tfidf_train, y_train, cv=5)))\n",
    "print(\"Confusion matrix : \\n {}\".format(confusion_matrix(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model fitted..\n",
      "Accuracy score : 0.9174463401210787\n",
      "Cross val score : [0.92707258 0.92397661 0.91812865 0.92085341 0.92085341]\n",
      "Confusion matrix : \n",
      " [[1787  264]\n",
      " [  36 1547]]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter = 500)\n",
    "lr.fit(tfidf_train, y_train)\n",
    "print('Logistic Regression model fitted..')\n",
    "\n",
    "pred = lr.predict(tfidf_test)\n",
    "print(\"Accuracy score : {}\".format(accuracy_score(y_test, pred)))\n",
    "print(\"Cross val score : {}\".format(cross_val_score(lr, tfidf_train, y_train, cv=5)))\n",
    "print(\"Confusion matrix : \\n {}\".format(confusion_matrix(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb = XGBClassifier()\n",
    "# xgb.fit(tfidf_train, y_train)\n",
    "\n",
    "# print('XGBoost Classifier model fitted..')\n",
    "# pred = xgb.predict(tfidf_test)\n",
    "# print(\"Accuracy score : {}\".format(accuracy_score(y_test, pred)))\n",
    "# print(\"Cross val score : {}\".format(cross_val_score(xgb, tfidf_train, y_train, cv=5)))\n",
    "# print(\"Confusion matrix : \\n {}\".format(confusion_matrix(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6224, number of negative: 8309\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29231\n",
      "[LightGBM] [Info] Number of data points in the train set: 14533, number of used features: 1214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.428267 -> initscore=-0.288926\n",
      "[LightGBM] [Info] Start training from score -0.288926\n",
      "LightGBM Classifier model fitted..\n",
      "Accuracy score : 0.9221243808475509\n",
      "[LightGBM] [Info] Number of positive: 4979, number of negative: 6647\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012884 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22623\n",
      "[LightGBM] [Info] Number of data points in the train set: 11626, number of used features: 953\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.428264 -> initscore=-0.288937\n",
      "[LightGBM] [Info] Start training from score -0.288937\n",
      "[LightGBM] [Info] Number of positive: 4979, number of negative: 6647\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22615\n",
      "[LightGBM] [Info] Number of data points in the train set: 11626, number of used features: 939\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.428264 -> initscore=-0.288937\n",
      "[LightGBM] [Info] Start training from score -0.288937\n",
      "[LightGBM] [Info] Number of positive: 4979, number of negative: 6647\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22586\n",
      "[LightGBM] [Info] Number of data points in the train set: 11626, number of used features: 947\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.428264 -> initscore=-0.288937\n",
      "[LightGBM] [Info] Start training from score -0.288937\n",
      "[LightGBM] [Info] Number of positive: 4979, number of negative: 6648\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22670\n",
      "[LightGBM] [Info] Number of data points in the train set: 11627, number of used features: 951\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.428227 -> initscore=-0.289087\n",
      "[LightGBM] [Info] Start training from score -0.289087\n",
      "[LightGBM] [Info] Number of positive: 4980, number of negative: 6647\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22588\n",
      "[LightGBM] [Info] Number of data points in the train set: 11627, number of used features: 944\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.428313 -> initscore=-0.288736\n",
      "[LightGBM] [Info] Start training from score -0.288736\n",
      "Cross val score : [0.92638459 0.92638459 0.92225662 0.93427392 0.92498279]\n",
      "Confusion matrix : \n",
      " [[1828  223]\n",
      " [  60 1523]]\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier()\n",
    "lgbm.fit(tfidf_train, y_train)\n",
    "\n",
    "print('LightGBM Classifier model fitted..')\n",
    "pred = lgbm.predict(tfidf_test)\n",
    "print(\"Accuracy score : {}\".format(accuracy_score(y_test, pred)))\n",
    "print(\"Cross val score : {}\".format(cross_val_score(lgbm, tfidf_train, y_train, cv=5)))\n",
    "print(\"Confusion matrix : \\n {}\".format(confusion_matrix(y_test, pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
